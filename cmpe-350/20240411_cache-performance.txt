Cache Memory Performance

---

Unified Memory (Data and Instructions) aka. Princeton Approach

Example:
Assumptions:
    30% Load / Store (Data access)
    Miss rate: 5% 
    Miss penalty: 100 cycles
    CPI_exec: 2 cycles (doesn't consider realistic memory access time)

What's the realistic CPI?
    CPI_real = CPI_exec + Memory stall per instruction
    Memory stall per instruction = (Instruction fetch * Miss rate * Miss penalty) + (Data access * Miss rate * Miss penalty)

    CPI_real = 2 + (1 * 0.05 * 100) + (0.3 * 0.05 * 100) 
             = 2 + 5 + 1.5 
             = 8.5 cycles

What's the speedup thanks to cache?
    Since no cache, the miss rate will be 100% for both data and instructions.
    CPI_real = 2 + (1 * 1 * 100) + (0.3 * 1 * 100) 
             = 2 + 100 + 30 
             = 132 cycles
    
    Speedup = 132 / 8.5 = 15.5

    15.5 times faster with cache

---

Separate Memory (Data and Instructions) aka. Harvard Approach

Example:
Assumptions:
    30% Load/Store
                  Instruction     Data Access
    Miss rate:    5%              10%
    Miss penalty: 100 cycles      100 cycles
    CPI_exec: 3 cycles

What's the realistic CPI?
    CPI_real = CPI_exec + Memory stall per instruction
    Memory stall per instruction = (Instruction fetch * Miss rate * Miss penalty) + (Data access * Miss rate * Miss penalty)

    CPI_real = 3 + (1 * 0.05 * 100) + (0.3 * 0.1 * 100) 
             = 3 + 5 + 3 
             = 11 cycles

What's the ideal speedup over real?
    speedup = CPI_real / CPI_exec
            = 11 / 3
            = 3.67 times faster

What's the speedup with only instruction cache?
    Since no cache, the miss rate will be 100% for instructions.
    CPI_real = 3 + (1 * 1 * 100) + (0.3 * 0.1 * 100) 
             = 3 + 100 + 3 
             = 106 cycles
    speedup = 106 / 11 = 9.63 times faster with cache
